import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras import layers, models

# ---- Sample Training Data (Dummy examples) ----
texts = [
    "Congratulations you won a free lottery",
    "Win money now click here",
    "Free prize claim now",
    "Urgent you have won cash reward",
    "Hello how are you",
    "Are we meeting tomorrow",
    "Please send the report",
    "Let's go for lunch"
]

labels = tf.constant([1,1,1,1,0,0,0,0])  # 1 = spam, 0 = not spam

# ---- Tokenizer & Padding ----
MAX_WORDS = 5000
MAX_LEN = 10

tok = Tokenizer(num_words=MAX_WORDS, oov_token="<OOV>")
tok.fit_on_texts(texts)

seq = tok.texts_to_sequences(texts)
pad = pad_sequences(seq, maxlen=MAX_LEN, padding="post")

# ---- Build the Model ----
model = models.Sequential([
    layers.Embedding(MAX_WORDS, 16),
    layers.GlobalAveragePooling1D(),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# ---- Train ----
model.fit(pad, labels, epochs=10, verbose=1)

# ---- Prediction Helper ----
def predict(text):
    s = tok.texts_to_sequences([text])
    p = pad_sequences(s, maxlen=MAX_LEN, padding="post")
    prob = float(model.predict(p, verbose=0)[0,0])
    print(f"\nInput: {text}")
    print("Prediction:", "SPAM" if prob >= 0.5 else "NOT SPAM", f"({prob:.4f})")

# ---- Test ----
predict("You won a free reward click now")
predict("Hi, are we still meeting today?")
